{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GCP_BQ_CREDENTIALS_FILE_PATH = os.environ['GCP_BQ_CREDENTIALS']\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    GCP_BQ_CREDENTIALS_FILE_PATH, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "first_in_year_tables = [\n",
    "    'httparchive.summary_requests.2018_01_01_desktop',\n",
    "    'httparchive.summary_requests.2019_02_01_desktop',\n",
    "    'httparchive.summary_requests.2020_01_01_desktop',\n",
    "    'httparchive.summary_requests.2021_01_01_desktop',\n",
    "    'httparchive.summary_requests.2022_01_01_desktop',\n",
    "    #'httparchive.summary_requests.2023_01_01_desktop'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "query_string = r'''\n",
    "WITH final_extracted_table AS (\n",
    "  WITH rt_extracted_values_table AS (\n",
    "    WITH nel_values_extracted_table AS (\n",
    "      WITH nel_extracted_table AS (\n",
    "        WITH joined_table AS (\n",
    "          WITH filtered_table AS (\n",
    "            SELECT\n",
    "            MIN(requestid) min_req_id,\n",
    "            #COUNTIF(firstReq = false) occurences_count_not_firstreq,\n",
    "            REGEXP_EXTRACT(url, r\"http[s]?:[\\/][\\/]([^\\/:]+)\") AS url_domain,\n",
    "            FROM `%s`\n",
    "            GROUP BY url_domain\n",
    "          )\n",
    "          SELECT\n",
    "          requestid,\n",
    "          LOWER(respOtherHeaders) resp_headers,\n",
    "          status,\n",
    "          url,\n",
    "          type,\n",
    "          ext,\n",
    "          firstReq,\n",
    "          FROM filtered_table\n",
    "          INNER JOIN `%s` ON filtered_table.min_req_id = requestid\n",
    "        )\n",
    "\n",
    "        SELECT\n",
    "        requestid,\n",
    "        type,\n",
    "        ext,\n",
    "        firstReq,\n",
    "        status,\n",
    "        url,\n",
    "        resp_headers,\n",
    "\n",
    "        (SELECT COUNT(*) FROM joined_table) AS unique_domain_count_before_filtration,\n",
    "        (SELECT COUNT(*) FROM joined_table WHERE firstReq = true) AS unique_domain_firstreq_count_before_filtration,\n",
    "        #REGEXP_EXTRACT(url, r\"http[s]?:[\\/][\\/]([^\\/:]+)\") AS url_domain,\n",
    "        REGEXP_CONTAINS(resp_headers, r\"(?:^|.*[\\s,]+)(nel\\s*[=]\\s*)\") AS contains_nel,\n",
    "        REGEXP_EXTRACT(resp_headers, r\"(?:^|.*[\\s,]+)nel\\s*[=]\\s*({.*?})\") AS nel_value,\n",
    "\n",
    "        FROM joined_table\n",
    "      )\n",
    "      SELECT\n",
    "      requestid,\n",
    "      type,\n",
    "      ext,\n",
    "      firstReq,\n",
    "      status,\n",
    "      url,\n",
    "      #url_domain,\n",
    "      unique_domain_count_before_filtration,\n",
    "      unique_domain_firstreq_count_before_filtration,\n",
    "      contains_nel,\n",
    "\n",
    "      nel_value,\n",
    "      resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "\n",
    "      # extract nel values\n",
    "      REGEXP_EXTRACT(nel_value, r\".*max_age[\\\"\\']\\s*:\\s*([0-9]+)\") AS nel_max_age,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*failure[_]fraction[\\\"\\']\\s*:\\s*([0-9\\.]+)\") AS nel_failure_fraction,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*success[_]fraction[\\\"\\']\\s*:\\s*([0-9\\.]+)\") AS nel_success_fraction,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*include[_]subdomains[\\\"\\']\\s*:\\s*(\\w+)\") AS nel_include_subdomains,\n",
    "\n",
    "      REGEXP_EXTRACT(nel_value, r\".*report_to[\\\"\\']\\s*:\\s*[\\\"\\'](.+?)[\\\"\\']\") AS nel_report_to_group,\n",
    "\n",
    "      FROM nel_extracted_table\n",
    "      WHERE contains_nel = true\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "    requestid,\n",
    "    type,\n",
    "    ext,\n",
    "    firstReq,\n",
    "    status,\n",
    "    url,\n",
    "    unique_domain_count_before_filtration,\n",
    "    unique_domain_firstreq_count_before_filtration,\n",
    "    contains_nel,\n",
    "    nel_max_age,\n",
    "    nel_failure_fraction,\n",
    "    nel_success_fraction,\n",
    "    nel_include_subdomains,\n",
    "    nel_report_to_group,\n",
    "    #nel_value, # debug rm\n",
    "    #reportto_value, # debug rm\n",
    "    resp_headers,\n",
    "\n",
    "    (SELECT COUNT(*) FROM nel_values_extracted_table) AS nel_count_before_filtration,\n",
    "\n",
    "    REGEXP_EXTRACT(resp_headers, CONCAT(r\"report[-]to\\s*?[=].*([{](?:(?:[^\\{]*?endpoints.*?[\\[][^\\[]*?[\\]][^\\}]*?)|(?:[^\\{]*?endpoints.*?[\\{][^\\{]*?[\\}]))?[^\\]\\}]*?group[\\'\\\"][:]\\s*?[\\'\\\"]\", nel_report_to_group, r\"(?:(?:[^\\}]*?endpoints[^\\}]*?[\\[][^\\[]*?[\\]][^\\{]*?)|(?:[^\\}]*?endpoints.*?[\\{][^\\{]*?[\\}]))?.*?[}])\")) AS rt_value,\n",
    "\n",
    "    FROM nel_values_extracted_table\n",
    "  )\n",
    "  SELECT\n",
    "  requestid,\n",
    "  type,\n",
    "  ext,\n",
    "  firstReq,\n",
    "  status,\n",
    "  url,\n",
    "  unique_domain_count_before_filtration,\n",
    "  unique_domain_firstreq_count_before_filtration,\n",
    "  contains_nel,\n",
    "  nel_max_age,\n",
    "  nel_failure_fraction,\n",
    "  nel_success_fraction,\n",
    "  nel_include_subdomains,\n",
    "  nel_report_to_group,\n",
    "  #nel_value, # debug rm\n",
    "  rt_value,\n",
    "  #resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "  nel_count_before_filtration,\n",
    "\n",
    "  REGEXP_EXTRACT(rt_value, r\".*group[\\\"\\']\\s*:\\s*[\\\"\\'](.+?)[\\\"\\']\") AS rt_group,\n",
    "\n",
    "  REGEXP_EXTRACT_ALL(rt_value, r\"url[\\\"\\']\\s*:\\s*[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/]([^\\/]+?)[\\\\]*?[\\/\\\"]\") AS rt_endpoints,\n",
    "  REGEXP_EXTRACT(rt_value, r\"url[\\\"\\']\\s*:\\s*[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/]([^\\/]+?)[\\\\]*?[\\/\\\"]\") AS rt_url,\n",
    "  REGEXP_EXTRACT(rt_value, r\"url[\\\"\\']\\s*:\\s*(?:[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/].*?([^\\.]+?[.][^\\.]+?)[\\\\]*?[\\/\\\"])\") AS rt_url_sld,\n",
    "\n",
    "  FROM rt_extracted_values_table\n",
    ")\n",
    "\n",
    "SELECT\n",
    "requestid,\n",
    "type,\n",
    "ext,\n",
    "firstReq,\n",
    "status,\n",
    "url,\n",
    "unique_domain_count_before_filtration,\n",
    "unique_domain_firstreq_count_before_filtration,\n",
    "contains_nel,\n",
    "nel_max_age,\n",
    "nel_failure_fraction,\n",
    "nel_success_fraction,\n",
    "nel_include_subdomains,\n",
    "nel_report_to_group,\n",
    "#nel_value, # debug rm\n",
    "#rt_value, # debug rm\n",
    "#resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "nel_count_before_filtration,\n",
    "rt_group,\n",
    "rt_endpoints,\n",
    "rt_url,\n",
    "rt_url_sld,\n",
    "\n",
    "FROM final_extracted_table\n",
    "# filter data to only those that we could parse, and that has both report_to and group matching\n",
    "# by analysis, the filtered out records contains either not json value, bad formating such as \\\" for json quotes, or are maybe improperly parsed by previous processing by table creators (no value, missing brackets)\n",
    "WHERE nel_report_to_group = rt_group and nel_report_to_group is not null and rt_group is not null;\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def processing_bytes_estimation(table_list, query_string):\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    sum_mb = 0\n",
    "\n",
    "    for table_name in table_list:\n",
    "        query_job = client.query(\n",
    "            (\n",
    "                query_string % (table_name, table_name)\n",
    "            ),\n",
    "            job_config=job_config,\n",
    "        )\n",
    "        processed_mb = query_job.total_bytes_processed/1024/1024\n",
    "        print(\"This query '{}' will process {} MB, {} GB.\".format(table_name, processed_mb, processed_mb/1024))\n",
    "        sum_mb += processed_mb\n",
    "\n",
    "    print()\n",
    "    print(\"Total will process {} MB, {} GB, {} TB\".format(sum_mb, sum_mb/1024, sum_mb/1024/1024))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This query 'httparchive.summary_requests.2018_01_01_desktop' will process 13927.265086174011 MB, 13.600844810716808 GB.\n",
      "This query 'httparchive.summary_requests.2019_02_01_desktop' will process 77438.0036869049 MB, 75.62305047549307 GB.\n",
      "This query 'httparchive.summary_requests.2020_01_01_desktop' will process 114220.82409381866 MB, 111.54377352911979 GB.\n",
      "This query 'httparchive.summary_requests.2021_01_01_desktop' will process 181130.83368301392 MB, 176.88557976856828 GB.\n",
      "This query 'httparchive.summary_requests.2022_01_01_desktop' will process 213867.11904144287 MB, 208.85460843890905 GB.\n",
      "\n",
      "Total will process 600584.0455913544 MB, 586.507857022807 GB, 0.572761579123835 TB\n"
     ]
    }
   ],
   "source": [
    "processing_bytes_estimation(first_in_year_tables, query_string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def run_queries_store_data(table_list, query_string) -> list:\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_list = []\n",
    "\n",
    "    for table_name in table_list:\n",
    "        query_job = client.query(\n",
    "            (\n",
    "                query_string % (table_name, table_name)\n",
    "            ),\n",
    "            job_config=job_config,\n",
    "        )\n",
    "\n",
    "        dst_tmp_table_dict = query_job.__dict__['_properties']['configuration']['query']['destinationTable']\n",
    "        dst_tmp_table_name = f'{dst_tmp_table_dict[\"projectId\"]}.{dst_tmp_table_dict[\"datasetId\"]}.{dst_tmp_table_dict[\"tableId\"]}'\n",
    "\n",
    "        tmp_df = query_job.to_dataframe()\n",
    "\n",
    "        tmp_df.to_parquet(f\"results/{table_name}.{dst_tmp_table_name}.parquet\")\n",
    "        job_list.append(query_job)\n",
    "\n",
    "    return job_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "job_list = run_queries_store_data(first_in_year_tables, query_string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QueryJob<project=httparchive-analysis-376406, location=US, id=28b7fcef-9153-40d4-b81b-e645e3c291a0>, QueryJob<project=httparchive-analysis-376406, location=US, id=a0a8fa28-aefe-40a5-a38e-29113fc3ed4d>, QueryJob<project=httparchive-analysis-376406, location=US, id=f5994ff6-0cc1-4361-9a37-92c1ded1a6f4>, QueryJob<project=httparchive-analysis-376406, location=US, id=30eaf400-5d8a-453d-a379-25e86760a7b8>, QueryJob<project=httparchive-analysis-376406, location=US, id=b2ca2950-724b-413d-9f25-e75cc1fa53f8>]\n"
     ]
    }
   ],
   "source": [
    "print(job_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n"
     ]
    }
   ],
   "source": [
    "print(\"asdf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
