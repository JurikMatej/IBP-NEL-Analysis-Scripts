{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GCP_BQ_CREDENTIALS_FILE_PATH = os.environ['GCP_BQ_CREDENTIALS']\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    GCP_BQ_CREDENTIALS_FILE_PATH, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "first_in_year_tables = [\n",
    "    'httparchive.summary_requests.2018_02_01_mobile',\n",
    "    'httparchive.summary_requests.2019_02_01_mobile',\n",
    "    'httparchive.summary_requests.2020_02_01_mobile',\n",
    "    'httparchive.summary_requests.2021_02_01_mobile',\n",
    "    'httparchive.summary_requests.2022_02_01_mobile',\n",
    "    'httparchive.summary_requests.2023_02_01_mobile'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "query_string = r'''\n",
    "WITH final_extracted_table AS (\n",
    "  WITH rt_extracted_values_table AS (\n",
    "    WITH nel_values_extracted_table AS (\n",
    "      WITH nel_extracted_table AS (\n",
    "        WITH joined_table AS (\n",
    "          WITH filtered_table AS (\n",
    "            SELECT\n",
    "            MIN(requestid) min_req_id,\n",
    "            #COUNTIF(firstReq = false) occurences_count_not_firstreq,\n",
    "            REGEXP_EXTRACT(url, r\"http[s]?:[\\/][\\/]([^\\/:]+)\") AS url_domain,\n",
    "            FROM `%s`\n",
    "            GROUP BY url_domain\n",
    "          )\n",
    "          SELECT\n",
    "          requestid,\n",
    "          LOWER(respOtherHeaders) resp_headers,\n",
    "          status,\n",
    "          url,\n",
    "          type,\n",
    "          ext,\n",
    "          firstReq,\n",
    "          FROM filtered_table\n",
    "          INNER JOIN `%s` ON filtered_table.min_req_id = requestid\n",
    "        )\n",
    "\n",
    "        SELECT\n",
    "        requestid,\n",
    "        type,\n",
    "        ext,\n",
    "        firstReq,\n",
    "        status,\n",
    "        url,\n",
    "        resp_headers,\n",
    "\n",
    "        (SELECT COUNT(*) FROM joined_table) AS unique_domain_count_before_filtration,\n",
    "        (SELECT COUNT(*) FROM joined_table WHERE firstReq = true) AS unique_domain_firstreq_count_before_filtration,\n",
    "        #REGEXP_EXTRACT(url, r\"http[s]?:[\\/][\\/]([^\\/:]+)\") AS url_domain,\n",
    "        REGEXP_CONTAINS(resp_headers, r\"(?:^|.*[\\s,]+)(nel\\s*[=]\\s*)\") AS contains_nel,\n",
    "        REGEXP_EXTRACT(resp_headers, r\"(?:^|.*[\\s,]+)nel\\s*[=]\\s*({.*?})\") AS nel_value,\n",
    "\n",
    "        FROM joined_table\n",
    "      )\n",
    "      SELECT\n",
    "      requestid,\n",
    "      type,\n",
    "      ext,\n",
    "      firstReq,\n",
    "      status,\n",
    "      url,\n",
    "      #url_domain,\n",
    "      unique_domain_count_before_filtration,\n",
    "      unique_domain_firstreq_count_before_filtration,\n",
    "      contains_nel,\n",
    "\n",
    "      nel_value,\n",
    "      resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "\n",
    "      # extract nel values\n",
    "      REGEXP_EXTRACT(nel_value, r\".*max_age[\\\"\\']\\s*:\\s*([0-9]+)\") AS nel_max_age,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*failure[_]fraction[\\\"\\']\\s*:\\s*([0-9\\.]+)\") AS nel_failure_fraction,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*success[_]fraction[\\\"\\']\\s*:\\s*([0-9\\.]+)\") AS nel_success_fraction,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*include[_]subdomains[\\\"\\']\\s*:\\s*(\\w+)\") AS nel_include_subdomains,\n",
    "\n",
    "      REGEXP_EXTRACT(nel_value, r\".*report_to[\\\"\\']\\s*:\\s*[\\\"\\'](.+?)[\\\"\\']\") AS nel_report_to_group,\n",
    "\n",
    "      FROM nel_extracted_table\n",
    "      WHERE contains_nel = true\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "    requestid,\n",
    "    type,\n",
    "    ext,\n",
    "    firstReq,\n",
    "    status,\n",
    "    url,\n",
    "    unique_domain_count_before_filtration,\n",
    "    unique_domain_firstreq_count_before_filtration,\n",
    "    contains_nel,\n",
    "    nel_max_age,\n",
    "    nel_failure_fraction,\n",
    "    nel_success_fraction,\n",
    "    nel_include_subdomains,\n",
    "    nel_report_to_group,\n",
    "    #nel_value, # debug rm\n",
    "    #reportto_value, # debug rm\n",
    "    resp_headers,\n",
    "\n",
    "    (SELECT COUNT(*) FROM nel_values_extracted_table) AS nel_count_before_filtration,\n",
    "\n",
    "    REGEXP_EXTRACT(resp_headers, CONCAT(r\"report[-]to\\s*?[=].*([{](?:(?:[^\\{]*?endpoints.*?[\\[][^\\[]*?[\\]][^\\}]*?)|(?:[^\\{]*?endpoints.*?[\\{][^\\{]*?[\\}]))?[^\\]\\}]*?group[\\'\\\"][:]\\s*?[\\'\\\"]\", nel_report_to_group, r\"(?:(?:[^\\}]*?endpoints[^\\}]*?[\\[][^\\[]*?[\\]][^\\{]*?)|(?:[^\\}]*?endpoints.*?[\\{][^\\{]*?[\\}]))?.*?[}])\")) AS rt_value,\n",
    "\n",
    "    FROM nel_values_extracted_table\n",
    "  )\n",
    "  SELECT\n",
    "  requestid,\n",
    "  type,\n",
    "  ext,\n",
    "  firstReq,\n",
    "  status,\n",
    "  url,\n",
    "  unique_domain_count_before_filtration,\n",
    "  unique_domain_firstreq_count_before_filtration,\n",
    "  contains_nel,\n",
    "  nel_max_age,\n",
    "  nel_failure_fraction,\n",
    "  nel_success_fraction,\n",
    "  nel_include_subdomains,\n",
    "  nel_report_to_group,\n",
    "  #nel_value, # debug rm\n",
    "  rt_value,\n",
    "  #resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "  nel_count_before_filtration,\n",
    "\n",
    "  REGEXP_EXTRACT(rt_value, r\".*group[\\\"\\']\\s*:\\s*[\\\"\\'](.+?)[\\\"\\']\") AS rt_group,\n",
    "\n",
    "  REGEXP_EXTRACT_ALL(rt_value, r\"url[\\\"\\']\\s*:\\s*[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/]([^\\/]+?)[\\\\]*?[\\/\\\"]\") AS rt_endpoints,\n",
    "  REGEXP_EXTRACT(rt_value, r\"url[\\\"\\']\\s*:\\s*[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/]([^\\/]+?)[\\\\]*?[\\/\\\"]\") AS rt_url,\n",
    "  REGEXP_EXTRACT(rt_value, r\"url[\\\"\\']\\s*:\\s*(?:[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/].*?([^\\.]+?[.][^\\.]+?)[\\\\]*?[\\/\\\"])\") AS rt_url_sld,\n",
    "\n",
    "  FROM rt_extracted_values_table\n",
    ")\n",
    "\n",
    "SELECT\n",
    "requestid,\n",
    "type,\n",
    "ext,\n",
    "firstReq,\n",
    "status,\n",
    "url,\n",
    "unique_domain_count_before_filtration,\n",
    "unique_domain_firstreq_count_before_filtration,\n",
    "contains_nel,\n",
    "nel_max_age,\n",
    "nel_failure_fraction,\n",
    "nel_success_fraction,\n",
    "nel_include_subdomains,\n",
    "nel_report_to_group,\n",
    "#nel_value, # debug rm\n",
    "#rt_value, # debug rm\n",
    "#resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "nel_count_before_filtration,\n",
    "rt_group,\n",
    "rt_endpoints,\n",
    "rt_url,\n",
    "rt_url_sld,\n",
    "\n",
    "FROM final_extracted_table\n",
    "# filter data to only those that we could parse, and that has both report_to and group matching\n",
    "# by analysis, the filtered out records contains either not json value, bad formating such as \\\" for json quotes, or are maybe improperly parsed by previous processing by table creators (no value, missing brackets)\n",
    "WHERE nel_report_to_group = rt_group and nel_report_to_group is not null and rt_group is not null;\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def processing_bytes_estimation(table_list, query_string):\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    sum_mb = 0\n",
    "\n",
    "    for table_name in table_list:\n",
    "        query_job = client.query(\n",
    "            (\n",
    "                query_string % (table_name, table_name)\n",
    "            ),\n",
    "            job_config=job_config,\n",
    "        )\n",
    "        processed_mb = query_job.total_bytes_processed/1024/1024\n",
    "        print(\"This query '{}' will process {} MB, {} GB.\".format(table_name, processed_mb, processed_mb/1024))\n",
    "        sum_mb += processed_mb\n",
    "\n",
    "    print()\n",
    "    print(\"Total will process {} MB, {} GB, {} TB\".format(sum_mb, sum_mb/1024, sum_mb/1024/1024))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This query 'httparchive.summary_requests.2018_02_01_mobile' will process 12779.238265037537 MB, 12.47972486820072 GB.\n",
      "This query 'httparchive.summary_requests.2019_02_01_mobile' will process 99190.25790596008 MB, 96.86548623628914 GB.\n",
      "This query 'httparchive.summary_requests.2020_02_01_mobile' will process 132271.23532485962 MB, 129.17112824693322 GB.\n",
      "This query 'httparchive.summary_requests.2021_02_01_mobile' will process 200293.90373802185 MB, 195.59951536916196 GB.\n",
      "This query 'httparchive.summary_requests.2022_02_01_mobile' will process 265011.81181812286 MB, 258.8005974786356 GB.\n",
      "This query 'httparchive.summary_requests.2023_02_01_mobile' will process 519405.28375053406 MB, 507.2317224126309 GB.\n",
      "\n",
      "Total will process 1228951.730802536 MB, 1200.1481746118516 GB, 1.1720197017693863 TB\n"
     ]
    }
   ],
   "source": [
    "processing_bytes_estimation(first_in_year_tables, query_string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def run_queries_store_data(table_list, query_string) -> list:\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_list = []\n",
    "\n",
    "    for table_name in table_list:\n",
    "        query_job = client.query(\n",
    "            (\n",
    "                query_string % (table_name, table_name)\n",
    "            ),\n",
    "            job_config=job_config,\n",
    "        )\n",
    "\n",
    "        dst_tmp_table_dict = query_job.__dict__['_properties']['configuration']['query']['destinationTable']\n",
    "        dst_tmp_table_name = f'{dst_tmp_table_dict[\"projectId\"]}.{dst_tmp_table_dict[\"datasetId\"]}.{dst_tmp_table_dict[\"tableId\"]}'\n",
    "\n",
    "        tmp_df = query_job.to_dataframe()\n",
    "\n",
    "        tmp_df.to_parquet(f\"results_mobile_all_feb/{table_name}.{dst_tmp_table_name}.parquet\")\n",
    "        job_list.append(query_job)\n",
    "\n",
    "    return job_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "job_list = run_queries_store_data(first_in_year_tables, query_string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QueryJob<project=httparchive-analysis-376406, location=US, id=16066179-45d4-45f4-bcde-000d447f7f1f>, QueryJob<project=httparchive-analysis-376406, location=US, id=e7fdf661-30db-4a15-9d3e-ce2b44134596>, QueryJob<project=httparchive-analysis-376406, location=US, id=84070d92-00ed-4dab-8ec5-5d703eae92b4>, QueryJob<project=httparchive-analysis-376406, location=US, id=6ac82781-da67-4963-932b-18048caeb0fc>, QueryJob<project=httparchive-analysis-376406, location=US, id=2cbb080e-fc15-4e3b-b9dc-ce165579a7d7>, QueryJob<project=httparchive-analysis-376406, location=US, id=0465611c-3388-47b1-a0cf-84f4f9179309>]\n"
     ]
    }
   ],
   "source": [
    "print(job_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n"
     ]
    }
   ],
   "source": [
    "print(\"asdf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
