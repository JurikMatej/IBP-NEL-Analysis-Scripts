{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GCP_BQ_CREDENTIALS_FILE_PATH = os.environ['GCP_BQ_CREDENTIALS']\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    GCP_BQ_CREDENTIALS_FILE_PATH, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "first_in_year_tables = [\n",
    "    'httparchive.summary_requests.2018_01_01_mobile',\n",
    "    'httparchive.summary_requests.2019_02_01_mobile',\n",
    "    'httparchive.summary_requests.2020_01_01_mobile',\n",
    "    'httparchive.summary_requests.2021_02_01_mobile',\n",
    "    'httparchive.summary_requests.2022_01_01_mobile',\n",
    "    'httparchive.summary_requests.2023_01_01_mobile'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "query_string = r'''\n",
    "WITH final_extracted_table AS (\n",
    "  WITH rt_extracted_values_table AS (\n",
    "    WITH nel_values_extracted_table AS (\n",
    "      WITH nel_extracted_table AS (\n",
    "        WITH joined_table AS (\n",
    "          WITH filtered_table AS (\n",
    "            SELECT\n",
    "            MIN(requestid) min_req_id,\n",
    "            #COUNTIF(firstReq = false) occurences_count_not_firstreq,\n",
    "            REGEXP_EXTRACT(url, r\"http[s]?:[\\/][\\/]([^\\/:]+)\") AS url_domain,\n",
    "            FROM `%s`\n",
    "            GROUP BY url_domain\n",
    "          )\n",
    "          SELECT\n",
    "          requestid,\n",
    "          LOWER(respOtherHeaders) resp_headers,\n",
    "          status,\n",
    "          url,\n",
    "          type,\n",
    "          ext,\n",
    "          firstReq,\n",
    "          FROM filtered_table\n",
    "          INNER JOIN `%s` ON filtered_table.min_req_id = requestid\n",
    "        )\n",
    "\n",
    "        SELECT\n",
    "        requestid,\n",
    "        type,\n",
    "        ext,\n",
    "        firstReq,\n",
    "        status,\n",
    "        url,\n",
    "        resp_headers,\n",
    "\n",
    "        (SELECT COUNT(*) FROM joined_table) AS unique_domain_count_before_filtration,\n",
    "        (SELECT COUNT(*) FROM joined_table WHERE firstReq = true) AS unique_domain_firstreq_count_before_filtration,\n",
    "        #REGEXP_EXTRACT(url, r\"http[s]?:[\\/][\\/]([^\\/:]+)\") AS url_domain,\n",
    "        REGEXP_CONTAINS(resp_headers, r\"(?:^|.*[\\s,]+)(nel\\s*[=]\\s*)\") AS contains_nel,\n",
    "        REGEXP_EXTRACT(resp_headers, r\"(?:^|.*[\\s,]+)nel\\s*[=]\\s*({.*?})\") AS nel_value,\n",
    "\n",
    "        FROM joined_table\n",
    "      )\n",
    "      SELECT\n",
    "      requestid,\n",
    "      type,\n",
    "      ext,\n",
    "      firstReq,\n",
    "      status,\n",
    "      url,\n",
    "      #url_domain,\n",
    "      unique_domain_count_before_filtration,\n",
    "      unique_domain_firstreq_count_before_filtration,\n",
    "      contains_nel,\n",
    "\n",
    "      nel_value,\n",
    "      resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "\n",
    "      # extract nel values\n",
    "      REGEXP_EXTRACT(nel_value, r\".*max_age[\\\"\\']\\s*:\\s*([0-9]+)\") AS nel_max_age,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*failure[_]fraction[\\\"\\']\\s*:\\s*([0-9\\.]+)\") AS nel_failure_fraction,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*success[_]fraction[\\\"\\']\\s*:\\s*([0-9\\.]+)\") AS nel_success_fraction,\n",
    "      REGEXP_EXTRACT(nel_value, r\".*include[_]subdomains[\\\"\\']\\s*:\\s*(\\w+)\") AS nel_include_subdomains,\n",
    "\n",
    "      REGEXP_EXTRACT(nel_value, r\".*report_to[\\\"\\']\\s*:\\s*[\\\"\\'](.+?)[\\\"\\']\") AS nel_report_to_group,\n",
    "\n",
    "      FROM nel_extracted_table\n",
    "      WHERE contains_nel = true\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "    requestid,\n",
    "    type,\n",
    "    ext,\n",
    "    firstReq,\n",
    "    status,\n",
    "    url,\n",
    "    unique_domain_count_before_filtration,\n",
    "    unique_domain_firstreq_count_before_filtration,\n",
    "    contains_nel,\n",
    "    nel_max_age,\n",
    "    nel_failure_fraction,\n",
    "    nel_success_fraction,\n",
    "    nel_include_subdomains,\n",
    "    nel_report_to_group,\n",
    "    #nel_value, # debug rm\n",
    "    #reportto_value, # debug rm\n",
    "    resp_headers,\n",
    "\n",
    "    (SELECT COUNT(*) FROM nel_values_extracted_table) AS nel_count_before_filtration,\n",
    "\n",
    "    REGEXP_EXTRACT(resp_headers, CONCAT(r\"report[-]to\\s*?[=].*([{](?:(?:[^\\{]*?endpoints.*?[\\[][^\\[]*?[\\]][^\\}]*?)|(?:[^\\{]*?endpoints.*?[\\{][^\\{]*?[\\}]))?[^\\]\\}]*?group[\\'\\\"][:]\\s*?[\\'\\\"]\", nel_report_to_group, r\"(?:(?:[^\\}]*?endpoints[^\\}]*?[\\[][^\\[]*?[\\]][^\\{]*?)|(?:[^\\}]*?endpoints.*?[\\{][^\\{]*?[\\}]))?.*?[}])\")) AS rt_value,\n",
    "\n",
    "    FROM nel_values_extracted_table\n",
    "  )\n",
    "  SELECT\n",
    "  requestid,\n",
    "  type,\n",
    "  ext,\n",
    "  firstReq,\n",
    "  status,\n",
    "  url,\n",
    "  unique_domain_count_before_filtration,\n",
    "  unique_domain_firstreq_count_before_filtration,\n",
    "  contains_nel,\n",
    "  nel_max_age,\n",
    "  nel_failure_fraction,\n",
    "  nel_success_fraction,\n",
    "  nel_include_subdomains,\n",
    "  nel_report_to_group,\n",
    "  #nel_value, # debug rm\n",
    "  rt_value,\n",
    "  #resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "  nel_count_before_filtration,\n",
    "\n",
    "  REGEXP_EXTRACT(rt_value, r\".*group[\\\"\\']\\s*:\\s*[\\\"\\'](.+?)[\\\"\\']\") AS rt_group,\n",
    "\n",
    "  REGEXP_EXTRACT_ALL(rt_value, r\"url[\\\"\\']\\s*:\\s*[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/]([^\\/]+?)[\\\\]*?[\\/\\\"]\") AS rt_endpoints,\n",
    "  REGEXP_EXTRACT(rt_value, r\"url[\\\"\\']\\s*:\\s*[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/]([^\\/]+?)[\\\\]*?[\\/\\\"]\") AS rt_url,\n",
    "  REGEXP_EXTRACT(rt_value, r\"url[\\\"\\']\\s*:\\s*(?:[\\\"\\']http[s]?:[\\\\]*?[\\/][\\\\]*?[\\/].*?([^\\.]+?[.][^\\.]+?)[\\\\]*?[\\/\\\"])\") AS rt_url_sld,\n",
    "\n",
    "  FROM rt_extracted_values_table\n",
    ")\n",
    "\n",
    "SELECT\n",
    "requestid,\n",
    "type,\n",
    "ext,\n",
    "firstReq,\n",
    "status,\n",
    "url,\n",
    "unique_domain_count_before_filtration,\n",
    "unique_domain_firstreq_count_before_filtration,\n",
    "contains_nel,\n",
    "nel_max_age,\n",
    "nel_failure_fraction,\n",
    "nel_success_fraction,\n",
    "nel_include_subdomains,\n",
    "nel_report_to_group,\n",
    "#nel_value, # debug rm\n",
    "#rt_value, # debug rm\n",
    "#resp_headers, # debug rm, todo: zceknout jestli jsou vsechny co rikaji ze contains_nel maji values\n",
    "nel_count_before_filtration,\n",
    "rt_group,\n",
    "rt_endpoints,\n",
    "rt_url,\n",
    "rt_url_sld,\n",
    "\n",
    "FROM final_extracted_table\n",
    "# filter data to only those that we could parse, and that has both report_to and group matching\n",
    "# by analysis, the filtered out records contains either not json value, bad formating such as \\\" for json quotes, or are maybe improperly parsed by previous processing by table creators (no value, missing brackets)\n",
    "WHERE nel_report_to_group = rt_group and nel_report_to_group is not null and rt_group is not null;\n",
    "\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def processing_bytes_estimation(table_list, query_string):\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    sum_mb = 0\n",
    "\n",
    "    for table_name in table_list:\n",
    "        query_job = client.query(\n",
    "            (\n",
    "                query_string % (table_name, table_name)\n",
    "            ),\n",
    "            job_config=job_config,\n",
    "        )\n",
    "        processed_mb = query_job.total_bytes_processed/1024/1024\n",
    "        print(\"This query '{}' will process {} MB, {} GB.\".format(table_name, processed_mb, processed_mb/1024))\n",
    "        sum_mb += processed_mb\n",
    "\n",
    "    print()\n",
    "    print(\"Total will process {} MB, {} GB, {} TB\".format(sum_mb, sum_mb/1024, sum_mb/1024/1024))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This query 'httparchive.summary_requests.2018_01_01_mobile' will process 12558.765709877014 MB, 12.264419638551772 GB.\n",
      "This query 'httparchive.summary_requests.2019_02_01_mobile' will process 99190.25790596008 MB, 96.86548623628914 GB.\n",
      "This query 'httparchive.summary_requests.2020_01_01_mobile' will process 128303.6568031311 MB, 125.29653984680772 GB.\n",
      "This query 'httparchive.summary_requests.2021_02_01_mobile' will process 200293.90373802185 MB, 195.59951536916196 GB.\n",
      "This query 'httparchive.summary_requests.2022_01_01_mobile' will process 269628.1539134979 MB, 263.3087440561503 GB.\n",
      "This query 'httparchive.summary_requests.2023_01_01_mobile' will process 532537.0127010345 MB, 520.055676465854 GB.\n",
      "\n",
      "Total will process 1242511.7507715225 MB, 1213.390381612815 GB, 1.1849515445437646 TB\n"
     ]
    }
   ],
   "source": [
    "processing_bytes_estimation(first_in_year_tables, query_string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def run_queries_store_data(table_list, query_string) -> list:\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_list = []\n",
    "\n",
    "    for table_name in table_list:\n",
    "        query_job = client.query(\n",
    "            (\n",
    "                query_string % (table_name, table_name)\n",
    "            ),\n",
    "            job_config=job_config,\n",
    "        )\n",
    "\n",
    "        dst_tmp_table_dict = query_job.__dict__['_properties']['configuration']['query']['destinationTable']\n",
    "        dst_tmp_table_name = f'{dst_tmp_table_dict[\"projectId\"]}.{dst_tmp_table_dict[\"datasetId\"]}.{dst_tmp_table_dict[\"tableId\"]}'\n",
    "\n",
    "        tmp_df = query_job.to_dataframe()\n",
    "\n",
    "        tmp_df.to_parquet(f\"results_desktop/{table_name}.{dst_tmp_table_name}.parquet\")\n",
    "        job_list.append(query_job)\n",
    "\n",
    "    return job_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "job_list = run_queries_store_data(first_in_year_tables, query_string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QueryJob<project=httparchive-analysis-376406, location=US, id=fdad511b-9d66-49d7-a2ab-c5db9a5d7d00>, QueryJob<project=httparchive-analysis-376406, location=US, id=5d3096fc-b74e-4934-96fe-d76f449f3d30>, QueryJob<project=httparchive-analysis-376406, location=US, id=b1303ef1-4282-444f-8d19-11125b056141>, QueryJob<project=httparchive-analysis-376406, location=US, id=6b356b68-ea16-41e5-bc7d-9d03c7060a3d>, QueryJob<project=httparchive-analysis-376406, location=US, id=b3e2384e-e073-449a-9209-2b19c58f67c8>, QueryJob<project=httparchive-analysis-376406, location=US, id=7cbd9fc2-b223-459b-bdb2-dd631242b022>]\n"
     ]
    }
   ],
   "source": [
    "print(job_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n"
     ]
    }
   ],
   "source": [
    "print(\"asdf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
